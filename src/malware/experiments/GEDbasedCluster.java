package malware.experiments;

import java.io.BufferedInputStream;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.util.ArrayList;
import java.util.BitSet;
import java.util.HashMap;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Scanner;

import malware.data.MicrosoftDatasetReaders;
import ml.cluster.AgglomerativeHierarchical;
import ml.cluster.AgglomerativeHierarchical.ProximityMetric;
import ml.cluster.Cluster;
import ml.cluster.DistanceFunction;
import ml.cluster.KMedoids;
import ml.cluster.KMedoids.CentroidInitialization;
import ml.data.Attribute;
import ml.data.Attribute.Type;
import ml.data.DataInstance;
import util.CommandLineArguments;
import util.Pair;
import util.UnorderedPair;

/***
 * Clusters malware samples based on the GED similarity. All instance similarity is given as an
 * input to this program(which is a CSV file where the first two columns are the instance IDs and
 * the third column is the approximated GED).
 * 
 * @author meha
 *
 */
public class GEDbasedCluster {

  public static void main(String[] args) throws FileNotFoundException {
    CommandLineArguments cmdArgs = new CommandLineArguments();
    cmdArgs.addOption(true, "-in", true); // Input folder path .csv file where first two columns
                                          // are the instance IDs and the third column is the
                                          // approximated GED.
    cmdArgs.addOption(true, "-label", true); // Path to class label info.
    cmdArgs.addOption(true, "-k", true); // Number of clusters
    cmdArgs.addOption(false, "-algo", true); // Cluster type (h for hierarchical| km for kMedoid)
                                             // kMedoid is the default.
    cmdArgs.addOption(false, "-maxIter", true); // Max number of iteration if algo doesnt converge.
    cmdArgs.addOption(false, "-init", true); // Centroid initialization for kmedoids (rand|plus).
                                             // Default=rand

    if (!cmdArgs.parseCommandLineArgs(args)) {
      System.out.println("Usage:\n\tjava GEDbasedCluster " + " -in input_folder "
          + " -label class_label_file -k num_of_clusters [-algo (h|km(default))]"
          + " [-maxIter maxIteration(default=5000)] " + " [-init (rand(default)|plus)].\n");
      return;
    }

    String inputPath = cmdArgs.getOptionValue("-in");
    String labelPath = cmdArgs.getOptionValue("-label");
    int k = Integer.parseInt(cmdArgs.getOptionValue("-k"));
    String algo = cmdArgs.getOptionValue("-algo") == null ? "km" : cmdArgs.getOptionValue("-algo");
    int maxIter = cmdArgs.getOptionValue("-maxIter") == null ? 5000
        : Integer.parseInt(cmdArgs.getOptionValue("-maxIter"));
    KMedoids.CentroidInitialization centerInit =
        cmdArgs.getOptionValue("-init") == null ? KMedoids.CentroidInitialization.RANDOM
            : cmdArgs.getOptionValue("-init").equalsIgnoreCase("plus")
                ? KMedoids.CentroidInitialization.PLUSPLUS : KMedoids.CentroidInitialization.RANDOM;

    File inputFile = new File(inputPath);
    if (!inputFile.exists()) {
      System.err.printf("ERROR: Input file '%s' does not exist!\n", inputPath);
      return;
    }

    File labelFile = new File(labelPath);
    if (!labelFile.exists()) {
      System.err.printf("ERROR: Input file '%s' does not exist!\n", labelPath);
      return;
    }

    // Cluster
    Pair<String, Integer>[] clusters = cluster(inputFile, k, algo, maxIter, centerInit);

    // Classify memebers
    List<Pair<String, String>> predictions = clusteringBasedClassification(clusters, labelFile);

    // Performance metric.
    System.out.printf("Classification Accuracy = %.2f%%\n",
        SupervisedPerformanceMetric.accuracy(predictions) * 100);
    System.out.println("\nConfusion Metrix:");
    System.out.println(SupervisedPerformanceMetric.confusionMatrix(predictions));
  }

  /***
   * Performs clustering based on the all pair proximity(distance) given in the input file.
   * 
   * @param inputFile a csv file formated as InstanceID1,InstanceID2,GraphEditDistance
   * @param k the number of final clusters.
   * @param centerInit
   * @param maxIter
   * @return cluster membership of each data instance.
   * @throws FileNotFoundException
   */
  private static Pair<String, Integer>[] cluster(File inputFile, int k, String algo, int maxIter,
      CentroidInitialization centerInit) throws FileNotFoundException {
    // Read similarity csv file
    String delimiter = "[,\\s]";
    List<Pair<UnorderedPair<String>, Double>> similarityList =
        readSimilarityList(inputFile, delimiter);

    // Initialize Distance function
    LookupDistanceFunction<String> distFn = initDistanceFunction(similarityList);

    // Create instances
    Pair<List<DataInstance>, List<Attribute>> dataAttributePair = organizeData(similarityList);
    List<DataInstance> data = dataAttributePair.getFirst();
    List<Attribute> attributeList = dataAttributePair.getSecond();


    List<Cluster> clusters = null;

    if (algo.equals("km")) {
      KMedoids clusterAlgo = new KMedoids(distFn, centerInit, maxIter);

      clusterAlgo.cluster(data, k, attributeList);
      clusters = clusterAlgo.getClusters();
    } else if (algo.equals("h")) {
      // Perform clustring
      AgglomerativeHierarchical clusterAlgo =
          new AgglomerativeHierarchical(distFn, ProximityMetric.CompleteLink);
      clusterAlgo.cluster(data, k, attributeList);
      clusters = clusterAlgo.getClusters();
    } else {
      System.err.printf("Error: Clustering algorithm '%s' not supported\n", algo);
      System.exit(1);
    }

    // Return cluster membership.
    Pair<String, Integer>[] clusterMembership = new Pair[data.size()];

    System.out.print("INFO: Size of clusters [");
    int i = 0;
    for (Cluster c : clusters) {
      BitSet members = c.getMembers();
      System.out.print(members.cardinality() + ", ");
      for (int j = members.nextSetBit(0); j > -1; j = members.nextSetBit(j + 1)) {
        clusterMembership[i++] =
            new Pair<String, Integer>((String) data.get(j).getAttributeValueAt(0), c.getId());
      }
    }
    System.out.println("]");

    return clusterMembership;
  }

  private static List<Pair<UnorderedPair<String>, Double>> readSimilarityList(File inputFile,
      String delimiter) throws FileNotFoundException {
    List<Pair<UnorderedPair<String>, Double>> list =
        new LinkedList<Pair<UnorderedPair<String>, Double>>();
    Scanner in = new Scanner(new BufferedInputStream(new FileInputStream(inputFile)));
    in.useDelimiter(delimiter);

    boolean first = true;

    while (in.hasNext()) {
      String graph1ID = in.next();
      String graph2ID = in.next();
      if (first) {
        first = false;
        if (!in.hasNextDouble()) {
          in.next();
          continue; // Skip Header
        }
      }
      list.add(new Pair<UnorderedPair<String>, Double>(
          new UnorderedPair<String>(graph1ID, graph2ID), in.nextDouble()));
    }
    in.close();
    return list;
  }

  private static LookupDistanceFunction<String> initDistanceFunction(
      List<Pair<UnorderedPair<String>, Double>> similarityList) {
    LookupDistanceFunction<String> distFn = new LookupDistanceFunction<String>();

    for (Pair<UnorderedPair<String>, Double> p : similarityList) {
      // Set distance to graph edit distance p.getSecond()
      distFn.addDistance(p.getFirst(), p.getSecond());
    }

    return distFn;
  }

  private static Pair<List<DataInstance>, List<Attribute>> organizeData(
      List<Pair<UnorderedPair<String>, Double>> similarityList) {
    List<Attribute> attributeList = new ArrayList<Attribute>();
    int attribIndex = 0;
    attributeList.add(new Attribute("id", attribIndex, Type.ID));

    int size = (int) Math.sqrt(similarityList.size()) * 2;

    HashSet<String> idSet = new HashSet<String>(size);

    for (Pair<UnorderedPair<String>, Double> p : similarityList) {
      idSet.add(p.getFirst().getFirst());
      idSet.add(p.getFirst().getSecond());
    }

    List<DataInstance> data = new ArrayList<DataInstance>(size);
    for (String s : idSet) {
      DataInstance d = new DataInstance();
      d.setAttributeValueAt(attribIndex, s);
      data.add(d);
    }

    return new Pair<List<DataInstance>, List<Attribute>>(data, attributeList);
  }

  /***
   * Classifies the cluster memebers based on the majority class in each cluster.
   * 
   * @param clusterMembership list containing a pair of elements of(instanceID, clusterID).
   * @param labelFile class label file.
   * @return
   * @throws FileNotFoundException
   */
  private static List<Pair<String, String>> clusteringBasedClassification(
      Pair<String, Integer>[] clusterMembership, File labelFile) throws FileNotFoundException {

    Map<String, String> classLabels = MicrosoftDatasetReaders.readClassLables(labelFile);

    // Find the class distribution for each cluster.
    // Maps clusterIDs --> an internal hash map.
    // Each internal maps classLabel --> Frequency i.e class distribution.
    HashMap<Integer, HashMap<String, Integer>> clusterClassDistribution =
        new HashMap<Integer, HashMap<String, Integer>>();

    for (Pair<String, Integer> p : clusterMembership) {
      String instanceID = p.getFirst();
      int clusterID = p.getSecond();

      String actualClassStr = classLabels.get(instanceID);
      if (actualClassStr == null) {
        continue;
      }

      // int actualClass = Integer.parseInt(actualClassStr);

      HashMap<String, Integer> cDist = clusterClassDistribution.get(clusterID);
      if (cDist == null) {
        cDist = new HashMap<String, Integer>(9);
        clusterClassDistribution.put(clusterID, cDist);
      }

      Integer count = cDist.get(actualClassStr);
      if (count == null) {
        count = 0;
      }
      cDist.put(actualClassStr, count + 1);
    }

    // Find the majority class in each cluster.
    HashMap<Integer, String> majorityClass =
        new HashMap<Integer, String>(clusterClassDistribution.size());
    for (Map.Entry<Integer, HashMap<String, Integer>> entry : clusterClassDistribution.entrySet()) {
      int clusterID = entry.getKey();
      HashMap<String, Integer> classDist = entry.getValue();

      int maxCount = 0;
      String maxClass = null;

      for (Map.Entry<String, Integer> innerEntry : classDist.entrySet()) {
        if (innerEntry.getValue() > maxCount) {
          maxCount = innerEntry.getValue();
          maxClass = innerEntry.getKey();
        }
      }
      majorityClass.put(clusterID, maxClass);
    }

    // Classify based on clustering.
    List<Pair<String, String>> predictions = new LinkedList<Pair<String, String>>();
    for (Pair<String, Integer> pair : clusterMembership) {
      String instanceID = pair.getFirst();
      int clusterID = pair.getSecond();

      String actualClassStr = classLabels.get(instanceID);
      if (actualClassStr == null) {
        continue;
      }

      predictions.add(new Pair<String, String>(actualClassStr, majorityClass.get(clusterID)));
    }

    return predictions;
  }

  public static class LookupDistanceFunction<I> implements DistanceFunction {
    HashMap<UnorderedPair<I>, Double> distanceMap;

    public LookupDistanceFunction() {
      distanceMap = new HashMap<UnorderedPair<I>, Double>(10);
    }

    public LookupDistanceFunction(int initialCapacity) {
      distanceMap = new HashMap<UnorderedPair<I>, Double>(initialCapacity);
    }

    public void addDistance(I instance1ID, I instance2ID, Double distance) {
      distanceMap.put(new UnorderedPair<I>(instance1ID, instance2ID), distance);
    }

    public void addDistance(UnorderedPair<I> idPair, Double distance) {
      distanceMap.put(idPair, distance);
    }

    @Override
    public double distance(DataInstance d1, DataInstance d2, List<Attribute> attributeList) {
      I first = (I) d1.getAttributeValueAt(0);
      I second = (I) d2.getAttributeValueAt(0);

      if (first.equals(second)) {
        return 0;
      }

      UnorderedPair<I> key = new UnorderedPair<I>(first, second);
      return distanceMap.get(key);
    }
  }

}
